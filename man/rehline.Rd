% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rehline.R
\name{rehline}
\alias{rehline}
\title{Solving Regularized Composite ReLU-ReHU Loss Minimization Problems}
\usage{
rehline(
  Xmat,
  Umat,
  Vmat,
  Smat = NULL,
  Tmat = NULL,
  Tau = Inf,
  Amat = NULL,
  bvec = NULL,
  max_iter = 1000,
  tol = 1e-05,
  shrink = TRUE,
  verbose = 0
)
}
\arguments{
\item{Xmat}{The data matrix \eqn{X=(x_1,\ldots,x_n)^T} of size
\eqn{n\times d}, representing \eqn{n} observations
and \eqn{d} features.}

\item{Umat, Vmat, Smat, Tmat}{The matrices \eqn{U=(u_{li})}, \eqn{V=(v_{li})},
\eqn{S=(s_{hi})}, and \eqn{T=(t_{hi})} in the
ReHLine optimization problem. Can be set to
\code{NULL}, meaning excluding the ReLU or ReHU
terms in the objective function.}

\item{Tau}{Either a numeric scalar, or an \eqn{H\times n} matrix
representing \eqn{\tau=(\tau_{hi})}.}

\item{Amat}{An \eqn{m\times d} matrix representing the
coefficients of \eqn{m} constraints. Can be
set to \code{NULL}, meaning no constraint is imposed.}

\item{bvec}{A length-\eqn{m} vector. Can be set to \code{NULL},
meaning no constraint is imposed.}

\item{max_iter}{Maximum number of iterations.}

\item{tol}{Tolerance parameter for convergence test.}

\item{shrink}{Whether to use the shrinkage algorithm.}

\item{verbose}{Level of verbosity.}
}
\value{
A list of the following components:
\item{beta}{Optimized value of the \eqn{\beta} vector.}
\item{xi,Lambda,Gamma}{Values of dual variables.}
\item{niter}{Number of iterations used.}
\item{dual_objfns}{Dual objective function values during the optimization process.}
}
\description{
This function solves the regularized composite ReLU-ReHU minimization
problem (called \emph{ReHLine optimization} for short) of the following form:
\deqn{
\min_{\beta}\ \sum_{i=1}^n \sum_{l=1}^L\mathrm{ReLU}(u_{li}x_i^T\beta+v_{li})+
\sum_{i=1}^n \sum_{h=1}^H\mathrm{ReHU}_{\tau_{hi}}(s_{hi}x_i^T\beta+t_{hi})+
\frac{1}{2}\Vert\beta\Vert^2
}
subject to general linear constraints \eqn{A\beta+b\ge 0},
where \eqn{\beta\in\mathbb{R}^d}{\beta} is a length-\eqn{d} vector,
\eqn{x_i\in\mathbb{R}^d} is the feature vector for the \eqn{i}-th observation,
\eqn{U=(u_{li})} and \eqn{V=(v_{li})} are \eqn{L\times n} matrices,
\eqn{S=(s_{hi})}, \eqn{T=(t_{hi})}, and \eqn{\tau=(\tau_{hi})} are
\eqn{H\times n} matrices, \eqn{A} is an \eqn{m\times d} matrix,
and \eqn{b} is a length-\eqn{m} vector.

The \eqn{\mathrm{ReLU}} function is \eqn{\mathrm{ReLU}(x)=\max(x, 0)},
and \eqn{\mathrm{ReHU}_\tau} is defined as
\deqn{
\mathrm{ReHU}_\tau(z)=
\begin{cases}
0,              & z\le 0 \\
z^2/2,          & 0<z\le\tau \\
\tau(z-\tau/2), & z>\tau
\end{cases}.
}

Many popular empirical risk minimization problems can be expressed
in the form of ReHLine optimization, such as SVM, quantile regression,
Huber regression, etc.
}
\author{
Yixuan Qiu \url{https://statr.me}

        Ben Dai \url{https://bendai.org}
}
